\section{Related Work}
\label{sec:related}
Sarcasm has been widely studied by psychologists, behavioral scientists and linguists for many years. Theories explaining the cognitive processes behind sarcasm usage such as the echoic reminder theory \cite{kreuz89}, allusional pretense theory \cite{kumon95}, and implicit display theory \cite{utsumi77} have been extensively researched. However, automatic detection of sarcasm is a relatively unexplored research topic and a challenging problem \cite{Pang2008}. While studies on automatic detection of sarcasm in speech \cite{tepper06} utilizes prosodic, spectral and contextual features, sarcasm detection in text has relied on identifying text patterns \cite{davidov10} and lexical features \cite{Kreuz07}.\\

Experiments with semi-supervised sarcasm identification on a Twitter dataset were conducted in \cite{davidov10}. They used 5-fold cross validation on their kNN-like classifier using mainly lexical features obtained an F-measure of 0.55 on the Twitter dataset. In \cite{davidov10}, authors use a semi-supervised sarcasm identification algorithm on a Twitter dataset and Amazon product reviews. In case of Twitter, authors mainly use $1500$ tweets containing \textit{\#sarcasm} hashtag and $180$ tweets tagged by $15$ Amazon Mechanical Turkers \cite{mturk} as golden test set or initial small labeled training set. The algorithm employs two modules: semi supervised pattern acquisition for identifying sarcastic patterns that serve as features for a classifier, and a classification stage that classifies each sentence to a sarcastic class. Reyes et al. \cite{reyes12} proposed features to capture properties of a figurative language such as ambiguity, polarity, unexpectedness and emotional scenarios. Their corpus consists of five categories (humor, irony, politics, technology and general), each containing 10,000 tweets. The best result in the classification of irony and general tweets was F-measure 0.65. Furthermore, Lukin and Walker \cite{Lukin_really13} explored the potential of a bootstrapping method for sarcasm classification in social dialogue to learn lexical N-gram cues associated with sarcasm (e.g., “oh really”, “I get it”, “no way”, etc.) as well as lexico-syntactic patterns. The work of Riloff et al. \cite{riloff13} identifies one type of sarcasm : contrast between a positive sentiment and negative situation. They used a bootstrapping algorithm to acquire lists of positive sentiment phrases and negative situation phrases from sarcastic tweets. Their evaluation on a human-annotated dataset of 3000 tweets (23\% sarcastic) was done using the SVM classifier with uni-grams and bigrams as features, achieving an F-measure of 0.48. \cite{gonzalez_acl} introduced a sarcasm detection technique using numerous lexical features (derived from LWIC \cite{pennebaker01} and Wordnet Affect \cite{valitutti04wordnet}) and pragmatic features such as emoticons and replies. Tomas et. al. \cite{tomas14} also tried to employ different combinations of machine learning approaches using language independent specific feature set on Czech and English Twitter dataset (780,000 tweets) and achieved F-measure around 0.94.